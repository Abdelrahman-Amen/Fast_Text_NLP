{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3316532,"sourceType":"datasetVersion","datasetId":10100}],"dockerImageVersionId":30685,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install fpdf","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:49:34.194325Z","iopub.execute_input":"2024-10-17T14:49:34.194962Z","iopub.status.idle":"2024-10-17T14:49:49.947681Z","shell.execute_reply.started":"2024-10-17T14:49:34.194932Z","shell.execute_reply":"2024-10-17T14:49:49.946614Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting fpdf\n  Downloading fpdf-1.7.2.tar.gz (39 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: fpdf\n  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40703 sha256=5e74d16fe754bef9484764bf8e0fffeaa4aea45d6d01926aac58487a536fd071\n  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\nSuccessfully built fpdf\nInstalling collected packages: fpdf\nSuccessfully installed fpdf-1.7.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport subprocess\nimport zipfile\nimport random\nimport string\nimport fasttext.util\nimport fasttext\nfrom gensim.models import FastText\nfrom tabulate import tabulate\nfrom gensim.models.fasttext import load_facebook_model\nfrom fpdf import FPDF\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:49:49.949514Z","iopub.execute_input":"2024-10-17T14:49:49.949816Z","iopub.status.idle":"2024-10-17T14:50:03.208212Z","shell.execute_reply.started":"2024-10-17T14:49:49.949787Z","shell.execute_reply":"2024-10-17T14:50:03.207345Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:03.209695Z","iopub.execute_input":"2024-10-17T14:50:03.210336Z","iopub.status.idle":"2024-10-17T14:50:03.471848Z","shell.execute_reply.started":"2024-10-17T14:50:03.210299Z","shell.execute_reply":"2024-10-17T14:50:03.470921Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Check if WordNet is available, if not, download it and extract\ntry:\n    nltk.data.find('corpora/wordnet.zip')\nexcept LookupError:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    with zipfile.ZipFile('/kaggle/working/corpora/wordnet.zip', 'r') as zip_ref:\n        zip_ref.extractall('/kaggle/working/corpora')\n    nltk.data.path.append('/kaggle/working/')\n\n# Now you can import wordnet from nltk.corpus\nfrom nltk.corpus import wordnet","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:03.473880Z","iopub.execute_input":"2024-10-17T14:50:03.474187Z","iopub.status.idle":"2024-10-17T14:50:03.830091Z","shell.execute_reply.started":"2024-10-17T14:50:03.474160Z","shell.execute_reply":"2024-10-17T14:50:03.829074Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Read json file","metadata":{}},{"cell_type":"code","source":"file_path=\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\"\ntips_data = []\nwith open(file_path, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        tips_data.append(json.loads(line))","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:03.831678Z","iopub.execute_input":"2024-10-17T14:50:03.832249Z","iopub.status.idle":"2024-10-17T14:50:10.000552Z","shell.execute_reply.started":"2024-10-17T14:50:03.832219Z","shell.execute_reply":"2024-10-17T14:50:09.999739Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# sample=tips_data[0]  \n# text=sample[\"text\"]\n# text","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:10.001627Z","iopub.execute_input":"2024-10-17T14:50:10.001939Z","iopub.status.idle":"2024-10-17T14:50:10.005919Z","shell.execute_reply.started":"2024-10-17T14:50:10.001915Z","shell.execute_reply":"2024-10-17T14:50:10.004893Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"text = []\nfor tip in tips_data:\n    #  I  Extract the \"text\" field from the tip and append it to the text list\n    text.append(tip['text'])","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:10.006944Z","iopub.execute_input":"2024-10-17T14:50:10.007214Z","iopub.status.idle":"2024-10-17T14:50:10.208791Z","shell.execute_reply.started":"2024-10-17T14:50:10.007191Z","shell.execute_reply":"2024-10-17T14:50:10.207971Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"samples=text[:100]\nsamples[:5]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:10.209811Z","iopub.execute_input":"2024-10-17T14:50:10.210078Z","iopub.status.idle":"2024-10-17T14:50:10.239809Z","shell.execute_reply.started":"2024-10-17T14:50:10.210040Z","shell.execute_reply":"2024-10-17T14:50:10.238933Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Avengers time with the ladies.',\n 'They have lots of good deserts and tasty cuban sandwiches',\n \"It's open even when you think it isn't\",\n 'Very decent fried chicken',\n 'Appetizers.. platter special for lunch']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Text Processing","metadata":{}},{"cell_type":"code","source":"                            # Tokenization\ntokenized_text = [word_tokenize(text) for text in samples]\n\n                            # Remove stop words\nstop_words = set(stopwords.words('english'))\nfiltered_text = []\nfor tokens in tokenized_text:\n    filtered_text.append([word for word in tokens if word.lower() not in stop_words])\n\n                            # Lemmatization\nlemmatizer = WordNetLemmatizer()\nlemmatized_text = []\nfor tokens in filtered_text:                                                                   # Remove punctuation\n    lemmatized_text.append([lemmatizer.lemmatize(word.lower()) for word in tokens if word not in string.punctuation])\n\n                            # Flatten the list of lists\npreprocessed_text = [word for sublist in lemmatized_text for word in sublist]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:10.241256Z","iopub.execute_input":"2024-10-17T14:50:10.241561Z","iopub.status.idle":"2024-10-17T14:50:12.603705Z","shell.execute_reply.started":"2024-10-17T14:50:10.241535Z","shell.execute_reply":"2024-10-17T14:50:12.602707Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(preprocessed_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:12.606658Z","iopub.execute_input":"2024-10-17T14:50:12.606963Z","iopub.status.idle":"2024-10-17T14:50:12.612799Z","shell.execute_reply.started":"2024-10-17T14:50:12.606935Z","shell.execute_reply":"2024-10-17T14:50:12.611837Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"601"},"metadata":{}}]},{"cell_type":"code","source":"preprocessed_text[:10]","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:12.614046Z","iopub.execute_input":"2024-10-17T14:50:12.614347Z","iopub.status.idle":"2024-10-17T14:50:12.624967Z","shell.execute_reply.started":"2024-10-17T14:50:12.614320Z","shell.execute_reply":"2024-10-17T14:50:12.624090Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['avenger',\n 'time',\n 'lady',\n 'lot',\n 'good',\n 'desert',\n 'tasty',\n 'cuban',\n 'sandwich',\n \"'s\"]"},"metadata":{}}]},{"cell_type":"markdown","source":"# FastText model using (Gensim)","metadata":{}},{"cell_type":"code","source":"# Train the FastText model\nmodel = FastText(sentences=[preprocessed_text], vector_size=100, window=5, min_count=1, workers=4, sg=1)\n\n                              # save the trained model\nmodel.save(\"fasttext_model\")\n\n# model = FastText.load(\"fasttext_model\")","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:12.625976Z","iopub.execute_input":"2024-10-17T14:50:12.626257Z","iopub.status.idle":"2024-10-17T14:50:14.335784Z","shell.execute_reply.started":"2024-10-17T14:50:12.626232Z","shell.execute_reply":"2024-10-17T14:50:14.335027Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Note:\n* ## min_count specifies the minimum count of words to consider when training the model.\n* ## workers specifies the number of worker threads to train the model.\n* ## sg is the training algorithm. sg=1 indicates skip-gram, while sg=0 indicates CBOW (Continuous Bag of Words).","metadata":{}},{"cell_type":"markdown","source":"### Select 10 random samples","metadata":{}},{"cell_type":"code","source":"# Select 10 random words from the preprocessed text\nrandom_words = random.sample(preprocessed_text, 10)\nrandom_words","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:14.336831Z","iopub.execute_input":"2024-10-17T14:50:14.337094Z","iopub.status.idle":"2024-10-17T14:50:14.343453Z","shell.execute_reply.started":"2024-10-17T14:50:14.337070Z","shell.execute_reply":"2024-10-17T14:50:14.342533Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['card',\n 'shuttle',\n 'anymore',\n 'sometimes',\n 'l',\n 'last',\n 'rally',\n 'cheeseburger',\n 'ring',\n 'inside']"},"metadata":{}}]},{"cell_type":"markdown","source":"# find similar and dissimilar words gensim function","metadata":{}},{"cell_type":"code","source":"def find_similar_and_dissimilar_words_gensim(word, model):\n    try:\n        # Find top 10 most similar words\n        similar_words = model.wv.most_similar(positive=[word], topn=10)\n\n        # Find top 10 most dissimilar words (opposite words)\n        dissimilar_words = model.wv.most_similar(negative=[word], topn=10)\n\n        return similar_words, dissimilar_words\n    except KeyError:\n        # Handle the case if the word is not in the vocabulary\n        return [], []\n\n# Iterate over each random word and find similar and dissimilar words\nfor word in random_words:\n    similar_words, dissimilar_words = find_similar_and_dissimilar_words_gensim(word, model)\n\n    if similar_words:\n        # Tabulate the similar words\n        table_similar = tabulate(similar_words, headers=['Similar Word', 'Similarity'], tablefmt='github')\n        print(f\"\\nTop 10 Similar Words for '{word}':\")\n        print(table_similar)\n\n    if dissimilar_words:\n        # Tabulate the dissimilar (opposite) words\n        table_dissimilar = tabulate(dissimilar_words, headers=['Dissimilar Word', 'Similarity'], tablefmt='github')\n        print(f\"\\nTop 10 Dissimilar Words for '{word}':\")\n        print(table_dissimilar)\n\n    print(\"\\n\" + \"-\" * 40 + \"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:14.344597Z","iopub.execute_input":"2024-10-17T14:50:14.344857Z","iopub.status.idle":"2024-10-17T14:50:14.402621Z","shell.execute_reply.started":"2024-10-17T14:50:14.344834Z","shell.execute_reply":"2024-10-17T14:50:14.401645Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nTop 10 Similar Words for 'card':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| carl           |     0.395454 |\n| restaurant     |     0.36008  |\n| orleans        |     0.312124 |\n| new            |     0.300653 |\n| many           |     0.291457 |\n| nice           |     0.277932 |\n| breakfast      |     0.276724 |\n| chalkboard     |     0.259243 |\n| starter        |     0.257331 |\n| cheese         |     0.250604 |\n\nTop 10 Dissimilar Words for 'card':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| incorrect         |     0.19468  |\n| easy              |     0.179817 |\n| hahaha            |     0.15579  |\n| bank              |     0.155541 |\n| friend            |     0.155388 |\n| 2013              |     0.152642 |\n| delicious         |     0.143214 |\n| time              |     0.13968  |\n| dont              |     0.136974 |\n| ugh               |     0.136965 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'shuttle':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| silver         |     0.34093  |\n| bathroom       |     0.276481 |\n| lunch/         |     0.266405 |\n| lunch          |     0.26397  |\n| fruit          |     0.255603 |\n| sharing        |     0.24897  |\n| yum            |     0.245306 |\n| fry            |     0.242778 |\n| hyper          |     0.237502 |\n| chicken        |     0.229833 |\n\nTop 10 Dissimilar Words for 'shuttle':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| yankee            |     0.233369 |\n| hot               |     0.216782 |\n| similar           |     0.201582 |\n| took              |     0.200492 |\n| even              |     0.19424  |\n| thanks            |     0.189714 |\n| ahead             |     0.18844  |\n| extra             |     0.183986 |\n| find              |     0.17248  |\n| bomb              |     0.166566 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'anymore':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| 2013           |     0.316908 |\n| fill           |     0.305188 |\n| chalkboard     |     0.268119 |\n| min            |     0.266825 |\n| pacer          |     0.252482 |\n| burger         |     0.248548 |\n| jr.            |     0.245567 |\n| jelly          |     0.239351 |\n| delicious      |     0.23043  |\n| city           |     0.228011 |\n\nTop 10 Dissimilar Words for 'anymore':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| buffet            |     0.328947 |\n| drew              |     0.204789 |\n| work              |     0.191854 |\n| steak             |     0.190689 |\n| brew              |     0.184195 |\n| 10                |     0.18155  |\n| ahead             |     0.178793 |\n| 's                |     0.168268 |\n| tampa             |     0.164893 |\n| glazed            |     0.16105  |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'sometimes':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| everything     |     0.299775 |\n| specialty      |     0.277378 |\n| michelob       |     0.275016 |\n| yum            |     0.274311 |\n| wing           |     0.274187 |\n| ...            |     0.258732 |\n| ever           |     0.251202 |\n| special        |     0.244391 |\n| brew           |     0.242723 |\n| definitely     |     0.241041 |\n\nTop 10 Dissimilar Words for 'sometimes':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| chip              |     0.224126 |\n| hotlight          |     0.216103 |\n| hoagy             |     0.204619 |\n| jr.               |     0.194061 |\n| italian           |     0.193195 |\n| lady              |     0.191764 |\n| basically         |     0.186764 |\n| fried             |     0.180837 |\n| took              |     0.17162  |\n| open              |     0.169104 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'l':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| chili          |     0.257068 |\n| negative       |     0.251458 |\n| day            |     0.247903 |\n| first          |     0.247853 |\n| mona           |     0.222123 |\n| dive           |     0.219906 |\n| stale          |     0.195551 |\n| helping        |     0.187668 |\n| sold           |     0.185696 |\n| desert         |     0.180762 |\n\nTop 10 Dissimilar Words for 'l':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| mini              |     0.283035 |\n| late              |     0.262949 |\n| yankee            |     0.252635 |\n| taste             |     0.234618 |\n| rally             |     0.219854 |\n| find              |     0.217867 |\n| jimmy             |     0.213727 |\n| buffalo           |     0.213647 |\n| place             |     0.210476 |\n| right             |     0.191031 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'last':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| parking        |     0.416715 |\n| approach       |     0.386655 |\n| nothing        |     0.365712 |\n| coast          |     0.329417 |\n| ring           |     0.313745 |\n| .meh           |     0.306943 |\n| nap            |     0.297593 |\n| spring         |     0.283964 |\n| america        |     0.280346 |\n| spicy          |     0.27592  |\n\nTop 10 Dissimilar Words for 'last':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| crowd             |     0.27549  |\n| soup              |     0.260855 |\n| evry              |     0.253893 |\n| place             |     0.23588  |\n| 6                 |     0.232805 |\n| try               |     0.218194 |\n| coupon            |     0.203993 |\n| pimento           |     0.187898 |\n| visit             |     0.172499 |\n| inside            |     0.170271 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'rally':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| really         |     0.486894 |\n| basically      |     0.424929 |\n| order          |     0.357526 |\n| spring         |     0.329687 |\n| n't            |     0.327611 |\n| cocktail       |     0.31837  |\n| friendly       |     0.308002 |\n| heberts        |     0.305989 |\n| friend         |     0.302969 |\n| burger         |     0.295743 |\n\nTop 10 Dissimilar Words for 'rally':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| l                 |     0.219854 |\n| folk              |     0.181017 |\n| small             |     0.166719 |\n| day               |     0.159084 |\n| service           |     0.137371 |\n| monday            |     0.129924 |\n| rush              |     0.129235 |\n| party             |     0.126753 |\n| white             |     0.122733 |\n| attendant         |     0.116613 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'cheeseburger':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| burger         |     0.710299 |\n| cheese         |     0.465288 |\n| order          |     0.450945 |\n| ordered        |     0.385973 |\n| really         |     0.380287 |\n| tasty          |     0.338007 |\n| ever           |     0.330528 |\n| hour           |     0.330451 |\n| location       |     0.330283 |\n| yum            |     0.329712 |\n\nTop 10 Dissimilar Words for 'cheeseburger':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| l                 |     0.159979 |\n| fav               |     0.151732 |\n| definitely        |     0.137234 |\n| chili             |     0.128531 |\n| 'll               |     0.124732 |\n| appetizers..      |     0.124683 |\n| thru              |     0.111533 |\n| stink             |     0.11001  |\n| italian           |     0.106964 |\n| ride              |     0.106714 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'ring':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| spring         |     0.565117 |\n| parking        |     0.477594 |\n| boring         |     0.476188 |\n| nothing        |     0.465409 |\n| bake           |     0.439701 |\n| wing           |     0.435252 |\n| spicy          |     0.420441 |\n| using          |     0.414256 |\n| really         |     0.383411 |\n| yummy          |     0.374815 |\n\nTop 10 Dissimilar Words for 'ring':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| vanilla           |     0.223258 |\n| evry              |     0.214895 |\n| worth             |     0.191276 |\n| peruvian          |     0.166466 |\n| please            |     0.164025 |\n| dive              |     0.161258 |\n| coupon            |     0.144576 |\n| friend            |     0.127058 |\n| fav               |     0.122557 |\n| environment       |     0.119726 |\n\n----------------------------------------\n\n\nTop 10 Similar Words for 'inside':\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| server         |     0.307182 |\n| ride           |     0.289871 |\n| college        |     0.2836   |\n| super          |     0.250873 |\n| train          |     0.24785  |\n| pepper         |     0.244803 |\n| real           |     0.243961 |\n| lol            |     0.232372 |\n| never          |     0.220511 |\n| turf           |     0.218671 |\n\nTop 10 Dissimilar Words for 'inside':\n| Dissimilar Word   |   Similarity |\n|-------------------|--------------|\n| shrimp            |     0.360873 |\n| used              |     0.242087 |\n| home              |     0.21652  |\n| jelly             |     0.202009 |\n| appetizers..      |     0.190887 |\n| cutlet            |     0.183566 |\n| thru              |     0.179513 |\n| much              |     0.172644 |\n| last              |     0.170271 |\n| 11:00             |     0.168006 |\n\n----------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# pre-trained FastText","metadata":{}},{"cell_type":"code","source":"# Download the pre-trained FastText word embeddings for English (300-dimensional vectors) from the Facebook AI repository\n! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n\n# Uncompress the downloaded file using gunzip, so that it can be used by the FastText library\n! gunzip \"cc.en.300.bin.gz\"","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:50:14.404095Z","iopub.execute_input":"2024-10-17T14:50:14.404706Z","iopub.status.idle":"2024-10-17T14:51:29.853285Z","shell.execute_reply.started":"2024-10-17T14:50:14.404670Z","shell.execute_reply":"2024-10-17T14:51:29.851871Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"--2024-10-17 14:50:15--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.51, 3.163.189.14, 3.163.189.96, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.51|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4503593528 (4.2G) [application/octet-stream]\nSaving to: 'cc.en.300.bin.gz'\n\ncc.en.300.bin.gz    100%[===================>]   4.19G   272MB/s    in 15s     \n\n2024-10-17 14:50:30 (288 MB/s) - 'cc.en.300.bin.gz' saved [4503593528/4503593528]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load pretrained fastText word embeddings\npretrained_fastText_en = load_facebook_model('/kaggle/working/cc.en.300.bin')","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:51:29.855123Z","iopub.execute_input":"2024-10-17T14:51:29.855470Z","iopub.status.idle":"2024-10-17T14:53:41.300268Z","shell.execute_reply.started":"2024-10-17T14:51:29.855438Z","shell.execute_reply":"2024-10-17T14:53:41.299384Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Generate PDF","metadata":{}},{"cell_type":"code","source":"# Example: Load pretrained fastText word embeddings (Uncomment for actual use)\n# pretrained_fastText_en = load_facebook_model('/kaggle/working/cc.en.300.bin')\n\nclass PDF(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, 'Word Similarity and Opposite Analysis', 0, 1, 'C')\n\n    def chapter_title(self, word):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, f'Analyzing word: {word}', 0, 1, 'L')\n\n    def chapter_body(self, title, table):\n        self.set_font('Arial', '', 12)\n        # Encode content in utf-8 to handle special characters\n        title_utf8 = title.encode('latin-1', 'replace').decode('latin-1')\n        table_utf8 = table.encode('latin-1', 'replace').decode('latin-1')\n        self.multi_cell(0, 10, f'{title_utf8}\\n{table_utf8}')\n        self.ln()\n        \n    def print_chapter(self, word, tables):\n        self.add_page()\n        self.chapter_title(word)\n        for title, table in tables.items():\n            self.chapter_body(title, table)\n\ndef analyze_word(word, model, model_name=\"custom model\"):\n    try:\n        # Get top 10 similar words\n        similar_words = model.wv.most_similar(word, topn=10)\n\n        # Get top 10 opposite words\n        opposite_words = model.wv.most_similar(negative=[word], topn=10)\n\n        # Create tables to display the results\n        table_similar = tabulate(similar_words, headers=['Similar Word', 'Similarity'], tablefmt='github')\n        table_opposite = tabulate(opposite_words, headers=['Opposite Word', 'Similarity'], tablefmt='github')\n\n        # Print the results in a formatted way\n        print(f\"Analyzing word: {word}\")\n        print(f\"\\nTop 10 similar words ({model_name}):\")\n        print(table_similar)\n        print(f\"\\nTop 10 opposite words ({model_name}):\")\n        print(table_opposite)\n        print(\"\\n\" + \"-\"*40 + \"\\n\")\n\n        return {\"Top 10 similar words\": table_similar, \"Top 10 opposite words\": table_opposite}\n    except KeyError:\n        print(f\"The word '{word}' is not in the model vocabulary.\")\n        return {}\n\ndef save_all_to_single_pdf(word_analysis, pdf_filename=\"word_similarity_analysis.pdf\"):\n    # Initialize the custom PDF class\n    pdf = PDF()\n    \n    # Add the analysis for each word to the PDF\n    for word, tables in word_analysis.items():\n        pdf.print_chapter(word, tables)\n    \n    # Output the final PDF\n    pdf.output(pdf_filename)\n\n# Example list of words to analyze (Uncomment for actual use)\n# random_words = ['silver', 'king', 'apple']    Simple Example\n\n# Dictionary to store analysis for all words\nword_analysis = {}\n\n# Iterate over each word and find similar and dissimilar words\nfor word in random_words:\n    # Analyze the word for the custom model\n    tables = analyze_word(word, pretrained_fastText_en, model_name=\"pretrained fastText model\")\n\n    if tables:  # Check if the analysis was successful (i.e., the word was found)\n        word_analysis[word] = tables  # Store the analysis in the dictionary\n\n# Save all analyses to a single PDF\nsave_all_to_single_pdf(word_analysis, pdf_filename=\"all_word_analysis.pdf\")","metadata":{"execution":{"iopub.status.busy":"2024-10-17T14:53:41.301591Z","iopub.execute_input":"2024-10-17T14:53:41.301882Z","iopub.status.idle":"2024-10-17T14:53:45.491206Z","shell.execute_reply.started":"2024-10-17T14:53:41.301857Z","shell.execute_reply":"2024-10-17T14:53:45.488234Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Analyzing word: card\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| cards          |     0.839138 |\n| card.The       |     0.794356 |\n| card.This      |     0.784574 |\n| card.I         |     0.781328 |\n| card.It        |     0.781021 |\n| card.So        |     0.777752 |\n| card.Now       |     0.77112  |\n| card.As        |     0.761264 |\n| card.What      |     0.759149 |\n| card.          |     0.758997 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| Coalbed         |     0.198198 |\n| Zhoukoudian     |     0.195917 |\n| Karangasem      |     0.195446 |\n| Navallur        |     0.18812  |\n| Median          |     0.187289 |\n| Buras           |     0.18142  |\n| Androctonus     |     0.181393 |\n| Mengwi          |     0.181197 |\n| EditAttach      |     0.180899 |\n| 00-05           |     0.175801 |\n\n----------------------------------------\n\nAnalyzing word: shuttle\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| shuttles       |     0.859319 |\n| Shuttle        |     0.768025 |\n| shuttle.       |     0.709487 |\n| Shuttles       |     0.689116 |\n| shuttle-bus    |     0.663285 |\n| shuttlebus     |     0.656225 |\n| shutle         |     0.618331 |\n| SHUTTLE        |     0.598845 |\n| space-shuttle  |     0.568181 |\n| mini-bus       |     0.546037 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| Monatsschrift   |     0.233325 |\n| Eisenmenger     |     0.181805 |\n| Comyns          |     0.179515 |\n| FittingsIAMPO   |     0.177557 |\n| MusicNovember   |     0.177453 |\n| Cases-          |     0.177324 |\n| Härtel          |     0.176921 |\n| Folk-Lore       |     0.176422 |\n| LondonHome      |     0.175167 |\n| PaleGreen       |     0.174318 |\n\n----------------------------------------\n\nAnalyzing word: anymore\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| anyway         |     0.683081 |\n| anyways        |     0.633517 |\n| anymore.I      |     0.621851 |\n| anymore-       |     0.602562 |\n| anymore.But    |     0.601924 |\n| anymore.And    |     0.600506 |\n| anyhow         |     0.596165 |\n| anylonger      |     0.59275  |\n| anymor         |     0.583388 |\n| But            |     0.582886 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| UnionA          |     0.235599 |\n| EmiratesBack    |     0.224128 |\n| 250-mL          |     0.219312 |\n| 1,015,000       |     0.216941 |\n| CRS-6           |     0.216277 |\n| NightQuestion   |     0.214742 |\n| Blitz04         |     0.211876 |\n| review20        |     0.210919 |\n| MMRT            |     0.210704 |\n| three-staged    |     0.210394 |\n\n----------------------------------------\n\nAnalyzing word: sometimes\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| often          |     0.824229 |\n| Sometimes      |     0.794093 |\n| oftentimes     |     0.74739  |\n| usually        |     0.746581 |\n| occasionally   |     0.715014 |\n| othertimes     |     0.698338 |\n| somtimes       |     0.675471 |\n| Often          |     0.668914 |\n| rarely         |     0.663653 |\n| often-times    |     0.642487 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| News0           |     0.244488 |\n| CentreNew       |     0.22458  |\n| 6-2Weight       |     0.223193 |\n| NewsLooking     |     0.219154 |\n| WebsiteNew      |     0.216215 |\n| Newsadmin       |     0.214294 |\n| Results4        |     0.213309 |\n| 20Board         |     0.212043 |\n| NewsLook        |     0.208851 |\n| 22New           |     0.208362 |\n\n----------------------------------------\n\nAnalyzing word: l\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| ztz            |     0.714965 |\n| h              |     0.70193  |\n| e              |     0.671782 |\n| r              |     0.666607 |\n| .l             |     0.652062 |\n| g              |     0.651182 |\n| li             |     0.649692 |\n| ike            |     0.644901 |\n| ou             |     0.64441  |\n| j              |     0.643637 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| things.All      |     0.19129  |\n| way.Quote       |     0.18004  |\n| SearchMetrics   |     0.177659 |\n| pretty-well     |     0.172671 |\n| on.New          |     0.170987 |\n| out.Buy         |     0.1704   |\n| all.Get         |     0.168647 |\n| unscratchable   |     0.166809 |\n| ballot-stuffing |     0.163486 |\n| good.Quote      |     0.161734 |\n\n----------------------------------------\n\nAnalyzing word: last\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| week           |     0.672012 |\n| year           |     0.665764 |\n| next           |     0.663572 |\n| year.Last      |     0.647755 |\n| first          |     0.647228 |\n| past           |     0.638695 |\n| Last           |     0.634244 |\n| month          |     0.632569 |\n| years.Last     |     0.631148 |\n| week.Last      |     0.627553 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word        |   Similarity |\n|----------------------|--------------|\n| SponsoredAXA         |     0.240765 |\n| 旅遊                 |     0.235292 |\n| SportsMember         |     0.230807 |\n| ToolsDeveloper       |     0.226361 |\n| 2Sales               |     0.223238 |\n| الوصف                |     0.221258 |\n| Rockets2Eating       |     0.221194 |\n| 1Construction        |     0.220694 |\n| ResourcesInformation |     0.220387 |\n| 􀁩                    |     0.217147 |\n\n----------------------------------------\n\nAnalyzing word: rally\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| rallies        |     0.820359 |\n| rally.The      |     0.764831 |\n| counter-rally  |     0.717448 |\n| rally.         |     0.706878 |\n| rallying       |     0.692274 |\n| pre-rally      |     0.688329 |\n| mini-rally     |     0.686625 |\n| rallys         |     0.682477 |\n| ralley         |     0.663915 |\n| Rally          |     0.65268  |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| PolicyFTC       |     0.227587 |\n| ACASS           |     0.202262 |\n| Vesica          |     0.201488 |\n| Benefits4.0Job  |     0.197328 |\n| ContactPrivacy  |     0.195983 |\n| ProceduresHead  |     0.194154 |\n| required.6.     |     0.191588 |\n| DisclaimerAbout |     0.191023 |\n| HOMEAbout       |     0.188378 |\n| AUTHORLINK      |     0.187445 |\n\n----------------------------------------\n\nAnalyzing word: cheeseburger\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| cheeseburgers  |     0.85284  |\n| cheesburger    |     0.817316 |\n| burger         |     0.811541 |\n| hamburger      |     0.783153 |\n| fries          |     0.73263  |\n| cheesburgers   |     0.72757  |\n| hamburgers     |     0.708886 |\n| McDouble       |     0.701585 |\n| bunless        |     0.699033 |\n| burgers        |     0.694741 |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word   |   Similarity |\n|-----------------|--------------|\n| Samuha          |     0.190596 |\n| Radev           |     0.189164 |\n| Workshops       |     0.186982 |\n| Central-Eastern |     0.184701 |\n| Leonte          |     0.181351 |\n| Mobilisation    |     0.180852 |\n| DotAsia         |     0.180683 |\n| Returnees       |     0.180204 |\n| Sinda           |     0.179774 |\n| Softex          |     0.179485 |\n\n----------------------------------------\n\nAnalyzing word: ring\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| rings          |     0.827629 |\n| ring.This      |     0.740662 |\n| ring.The       |     0.73695  |\n| ring.          |     0.724575 |\n| ring.It        |     0.722723 |\n| ring-          |     0.706352 |\n| ring.I         |     0.689525 |\n| ring.If        |     0.668783 |\n| ring.A         |     0.666687 |\n| Ring           |     0.64734  |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word    |   Similarity |\n|------------------|--------------|\n| 2017.1           |     0.225347 |\n| RSUST            |     0.211532 |\n| CyberLink        |     0.207299 |\n| Chenab           |     0.198744 |\n| Redistributables |     0.198675 |\n| awayWisconsin    |     0.198465 |\n| VectorWorks      |     0.196454 |\n| workersGuidance  |     0.194079 |\n| Resumen          |     0.19241  |\n| RatesRate        |     0.189205 |\n\n----------------------------------------\n\nAnalyzing word: inside\n\nTop 10 similar words (pretrained fastText model):\n| Similar Word   |   Similarity |\n|----------------|--------------|\n| outside        |     0.745039 |\n| insde          |     0.631733 |\n| insode         |     0.62667  |\n| inside.The     |     0.621846 |\n| outisde        |     0.619583 |\n| ouside         |     0.617253 |\n| Inside         |     0.614435 |\n| insdie         |     0.611482 |\n| insided        |     0.600545 |\n| underneath     |     0.59411  |\n\nTop 10 opposite words (pretrained fastText model):\n| Opposite Word     |   Similarity |\n|-------------------|--------------|\n| 2017Level         |     0.216723 |\n| MLDA              |     0.210085 |\n| Sharel            |     0.206886 |\n| .Monthly          |     0.206265 |\n| 2006C             |     0.205298 |\n| CRARY             |     0.201954 |\n| CLLS              |     0.199595 |\n| ReservationSelect |     0.198864 |\n| William3          |     0.198128 |\n| JOHN3             |     0.196841 |\n\n----------------------------------------\n\n","output_type":"stream"}]}]}